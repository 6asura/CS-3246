{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrxbKKJZtPzj"
      },
      "source": [
        "# **Activity 2: Python-Pandas Exercise**\n",
        "\n",
        "Objectives:\n",
        "- Understand Python syntax (variables, loops, functions).\n",
        "- Learn Pandas basics (Series, DataFrames, reading files).\n",
        "- Perform data cleaning (handling missing values, correcting formats, removing duplicates).\n",
        "- Apply concepts in a real-world case study."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNQbxlCPtvXZ"
      },
      "source": [
        "# Part 1: Hands-on Python & Pandas Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH2WqeaY38NC"
      },
      "source": [
        "1. Install the Pandas library in your environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPhWF_2u5Qxy"
      },
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZC17Lf1zT3Q"
      },
      "source": [
        "2. Import the  pandas package under the name `pd`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lR6fv9XE3Pw3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO_MlGtx3Wj5"
      },
      "source": [
        "3. Print the pandas version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Y4lcL4Nb3SrJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.2.3\n"
          ]
        }
      ],
      "source": [
        "print(pd.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWJFiRZ03pwH"
      },
      "source": [
        "4. Create a variable `x` with the value 10 and a string variable `y` with \"Fortes in Fide!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QCkALKg_3vig"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 Fortes in Fide!\n"
          ]
        }
      ],
      "source": [
        "x = 10\n",
        "y = \"Fortes in Fide!\"\n",
        "\n",
        "print(x,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBzRK3sY5Wfh"
      },
      "source": [
        "5. Define a list with numbers `[1, 2, 3, 4, 5]` and a dictionary with keys `name` and `age`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "s8Zg7dgz5XPA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "name    jemriz\n",
            "age         18\n",
            "dtype: object 0    1\n",
            "1    2\n",
            "2    3\n",
            "3    4\n",
            "4    5\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "numbers = [1, 2, 3, 4, 5]\n",
        "\n",
        "person = {\"name\" : \"jemriz\", \"age\" : 18}\n",
        "\n",
        "myPerson = pd.Series(person)\n",
        "myNumbers = pd.Series(numbers)\n",
        "\n",
        "print(myPerson, myNumbers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbsHcq7w5hE2"
      },
      "source": [
        "6. Write a function `greet(name)` that returns \"Magis, (name)\"!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LHKMev_a5mJX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Magis, Shan!\n"
          ]
        }
      ],
      "source": [
        "def greet(name):\n",
        "    return f\"Magis, {name}!\"\n",
        "\n",
        "print(greet(\"Shan\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_UBbRZKYBFF"
      },
      "source": [
        "7. Write a Python function that takes a userâ€™s name as input and prints a personalized greeting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-8T6ocVeYCnD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello, shan!\n"
          ]
        }
      ],
      "source": [
        "def greet_User():\n",
        "    user_name = input(\"Enter your name: \")\n",
        "    print(f\"Hello, {user_name}!\")\n",
        "\n",
        "greet_User()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GEjHQ-PYRj2"
      },
      "source": [
        "8. Modify **Number 7** that if the user does not enter a name, it defaults to \"Guest\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rYfMyyQeYbf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello, Guest!\n"
          ]
        }
      ],
      "source": [
        "def greet_User():\n",
        "    name = input(\"Enter your name: \").strip()  # Remove leading/trailing spaces\n",
        "    if not name:  # If the input is empty, assign \"Guest\"\n",
        "        name = \"Guest\"\n",
        "    print(f\"Hello, {name}!\")\n",
        "\n",
        "# Call the function to execute\n",
        "greet_User()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG-Ubf3259sb"
      },
      "source": [
        "9. Create a Pandas Series from `[10, 20, 30, 40]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oGThKfqQ5-sj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    10\n",
            "1    20\n",
            "2    30\n",
            "3    40\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "a = [10, 20, 30, 40]\n",
        "\n",
        "myvar = pd.Series(a)\n",
        "\n",
        "print(myvar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeSr_ozS6Wc5"
      },
      "source": [
        "10.  Create a DataFrame with columns `A` and `B`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ytbYen7w6Mmv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    A   B\n",
            "0  40  10\n",
            "1  50  20\n",
            "2  60  30\n"
          ]
        }
      ],
      "source": [
        "data = {\n",
        "    \"A\":[40,50,60],\n",
        "    \"B\": [10,20,30]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mAive8s7kfU"
      },
      "source": [
        "# Part 2: Working with a Dataset ðŸ›¥ï¸"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6daMs_F8SPx"
      },
      "source": [
        "1. Load the Titanic dataset from a local file and display the first five rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zi-ufFmj9e4h"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0          892         0       3   \n",
            "1          893         1       3   \n",
            "2          894         0       2   \n",
            "3          895         0       3   \n",
            "4          896         1       3   \n",
            "\n",
            "                                           Name     Sex   Age  SibSp  Parch  \\\n",
            "0                              Kelly, Mr. James    male  34.5      0      0   \n",
            "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
            "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
            "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
            "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
            "\n",
            "    Ticket     Fare Cabin Embarked  \n",
            "0   330911   7.8292   NaN        Q  \n",
            "1   363272   7.0000   NaN        S  \n",
            "2   240276   9.6875   NaN        Q  \n",
            "3   315154   8.6625   NaN        S  \n",
            "4  3101298  12.2875   NaN        S  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "file_path = \"dataset/titanic_dataset.csv\"  \n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "405AKURC9sqB"
      },
      "source": [
        "2. Display the dataset's column names, data types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "88-8AT8W9uaI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Column names:\n",
            "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
            "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
            "      dtype='object')\n",
            "\n",
            "Data Types:\n",
            "PassengerId      int64\n",
            "Survived         int64\n",
            "Pclass           int64\n",
            "Name            object\n",
            "Sex             object\n",
            "Age            float64\n",
            "SibSp            int64\n",
            "Parch            int64\n",
            "Ticket          object\n",
            "Fare           float64\n",
            "Cabin           object\n",
            "Embarked        object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "file_path = \"dataset/titanic_dataset.csv\"  \n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(\"Column names:\")\n",
        "print(df.columns)\n",
        "\n",
        "print(\"\\nData Types:\")\n",
        "print(df.dtypes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh9FsKUx9-8S"
      },
      "source": [
        "3. Display the dataset's missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "olw7wFVH9-rG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing Values in Each Column:\n",
            "Age       86\n",
            "Fare       1\n",
            "Cabin    327\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "file_path = \"dataset/titanic_dataset.csv\"  \n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "\n",
        "print(\"Missing Values in Each Column:\")\n",
        "print(missing_values[missing_values > 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNAGBAXv-LXs"
      },
      "source": [
        "4. Display the `Name`, `Age`, and `Fare` columns from the dataset. (first 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "LNRu6hI7-dUV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Name', 'Age', 'Fare']\n",
            "                                            Name   Age     Fare\n",
            "0                               Kelly, Mr. James  34.5   7.8292\n",
            "1               Wilkes, Mrs. James (Ellen Needs)  47.0   7.0000\n",
            "2                      Myles, Mr. Thomas Francis  62.0   9.6875\n",
            "3                               Wirz, Mr. Albert  27.0   8.6625\n",
            "4   Hirvonen, Mrs. Alexander (Helga E Lindqvist)  22.0  12.2875\n",
            "5                     Svensson, Mr. Johan Cervin  14.0   9.2250\n",
            "6                           Connolly, Miss. Kate  30.0   7.6292\n",
            "7                   Caldwell, Mr. Albert Francis  26.0  29.0000\n",
            "8      Abrahim, Mrs. Joseph (Sophie Halaut Easu)  18.0   7.2292\n",
            "9                        Davies, Mr. John Samuel  21.0  24.1500\n",
            "10                              Ilieff, Mr. Ylio   NaN   7.8958\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "file_path = \"dataset/titanic_dataset.csv\"  \n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "columns_to_display = [\"Name\", \"Age\", \"Fare\"]\n",
        "df_selected = df[columns_to_display].head(11)\n",
        "\n",
        "print(columns_to_display)\n",
        "print(df_selected)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2iFTTa2-nAv"
      },
      "source": [
        " 5. Print the descriptive statistics of the Titanic dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "VvurbDoL-xJE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
            "count   418.000000  418.000000  418.000000  332.000000  418.000000   \n",
            "mean   1100.500000    0.363636    2.265550   30.272590    0.447368   \n",
            "std     120.810458    0.481622    0.841838   14.181209    0.896760   \n",
            "min     892.000000    0.000000    1.000000    0.170000    0.000000   \n",
            "25%     996.250000    0.000000    1.000000   21.000000    0.000000   \n",
            "50%    1100.500000    0.000000    3.000000   27.000000    0.000000   \n",
            "75%    1204.750000    1.000000    3.000000   39.000000    1.000000   \n",
            "max    1309.000000    1.000000    3.000000   76.000000    8.000000   \n",
            "\n",
            "            Parch        Fare  \n",
            "count  418.000000  417.000000  \n",
            "mean     0.392344   35.627188  \n",
            "std      0.981429   55.907576  \n",
            "min      0.000000    0.000000  \n",
            "25%      0.000000    7.895800  \n",
            "50%      0.000000   14.454200  \n",
            "75%      0.000000   31.500000  \n",
            "max      9.000000  512.329200  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "file_path = \"dataset/titanic_dataset.csv\"  \n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "df_statistics = df.describe()\n",
        "\n",
        "print(df_statistics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U95dijMI-9x1"
      },
      "source": [
        "6. Remove rows with missing values in the `Age` column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "mMKNND-E_jnL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0          892         0       3   \n",
            "1          893         1       3   \n",
            "2          894         0       2   \n",
            "3          895         0       3   \n",
            "4          896         1       3   \n",
            "\n",
            "                                           Name     Sex   Age  SibSp  Parch  \\\n",
            "0                              Kelly, Mr. James    male  34.5      0      0   \n",
            "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
            "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
            "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
            "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
            "\n",
            "    Ticket     Fare Cabin Embarked  \n",
            "0   330911   7.8292   NaN        Q  \n",
            "1   363272   7.0000   NaN        S  \n",
            "2   240276   9.6875   NaN        Q  \n",
            "3   315154   8.6625   NaN        S  \n",
            "4  3101298  12.2875   NaN        S  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "file_path = \"dataset/titanic_dataset.csv\"  \n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "df_cleaned = df.dropna(subset=[\"Age\"])\n",
        "\n",
        "print(df_cleaned.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-2X_e-fFHI5"
      },
      "source": [
        "7. Remove duplicate rows from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "l2X-ym9eFIT-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0          892         0       3   \n",
            "1          893         1       3   \n",
            "2          894         0       2   \n",
            "3          895         0       3   \n",
            "4          896         1       3   \n",
            "\n",
            "                                           Name     Sex   Age  SibSp  Parch  \\\n",
            "0                              Kelly, Mr. James    male  34.5      0      0   \n",
            "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
            "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
            "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
            "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
            "\n",
            "    Ticket     Fare Cabin Embarked  \n",
            "0   330911   7.8292   NaN        Q  \n",
            "1   363272   7.0000   NaN        S  \n",
            "2   240276   9.6875   NaN        Q  \n",
            "3   315154   8.6625   NaN        S  \n",
            "4  3101298  12.2875   NaN        S  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "file_path = \"dataset/titanic_dataset.csv\"  \n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "df_no_duplicates = df.drop_duplicates()\n",
        "\n",
        "print(df_no_duplicates.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-SvrKnKFL1m"
      },
      "source": [
        "8. Compute and display the correlation matrix of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'Kelly, Mr. James'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[28], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset/titanic_dataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m  \n\u001b[0;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[1;32m----> 8\u001b[0m correlation_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(correlation_matrix)\n",
            "File \u001b[1;32mc:\\Users\\jaadvincula\\Desktop\\CS-3246\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:11049\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[1;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[0;32m  11047\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m  11048\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m> 11049\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m  11051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  11052\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
            "File \u001b[1;32mc:\\Users\\jaadvincula\\Desktop\\CS-3246\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:1993\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1992\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[1;32m-> 1993\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[0;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
            "File \u001b[1;32mc:\\Users\\jaadvincula\\Desktop\\CS-3246\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1694\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1692\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1694\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
            "File \u001b[1;32mc:\\Users\\jaadvincula\\Desktop\\CS-3246\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1753\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1752\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[1;32m-> 1753\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   1754\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
            "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Kelly, Mr. James'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "file_path = \"dataset/titanic_dataset.csv\"  \n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "print(correlation_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "1 df.corr() only computes correlations for numerical columns like integers and floats.\n",
        "\n",
        "2 When pandas tries to convert all columns into numerical values, it encounters a string (\"Kelly, Mr. James\") and raises a ValueError."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v_OG5PPLUcL"
      },
      "source": [
        "# Part 2: Working with Case Studies\n",
        "\n",
        "When working on these case studies, **always ensure that your code is properly documented and clearly presented**. Follow these key principles:  \n",
        "\n",
        "### **1. Always Show Your Code**  \n",
        "- Every step of data exploration, cleaning, and analysis should include **visible code outputs**.  \n",
        "- Do not skip showing your process, as transparency is essential for reproducibility.  \n",
        "\n",
        "### **2. Proper Documentation is Necessary**  \n",
        "- Use **comments (`#`) in Python** to explain your code clearly.  \n",
        "- Add **Markdown cells** to describe each step before executing the code.  \n",
        "- Explain key findings in simple language to make the analysis easy to understand.  \n",
        "\n",
        "### **3. Use Readable and Organized Code**  \n",
        "- Follow a **step-by-step approach** to keep the notebook structured.  \n",
        "- Use **proper variable names** and avoid hardcoding values where possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOzxo0NoFZJ5"
      },
      "source": [
        "# **Case Study 1: Iris Flower Classification** ðŸŒ¸  \n",
        "\n",
        "### **Background**  \n",
        "A botanical research institute wants to develop an automated system that classifies different species of **iris flowers** based on their **sepal and petal measurements**.  The dataset consists of **150 samples**, labeled as **Setosa, Versicolor, or Virginica**.  \n",
        "\n",
        "### **Problem Statement**  \n",
        "Can we use **sepal and petal dimensions** to correctly classify the **species of an iris flower**?  \n",
        "\n",
        "### **Task Description**  \n",
        "\n",
        "#### **1. Data Exploration**  \n",
        "- Load the dataset and display the first few rows.  \n",
        "- Identify any missing or inconsistent values.  \n",
        "\n",
        "#### **2. Data Cleaning**  \n",
        "- Check for missing values and handle them appropriately.  \n",
        "- Convert categorical species labels into a format suitable for analysis.  \n",
        "\n",
        "#### **3. Basic Data Analysis**  \n",
        "- Find the average sepal and petal dimensions for each species.  \n",
        "- Identify correlations between different flower measurements.  \n",
        "\n",
        "#### **4. Visualization**  \n",
        "- Create simple visualizations (e.g., histograms, scatter plots) to understand data distribution.  \n",
        "\n",
        "#### **5. Insights & Interpretation**  \n",
        "- Summarize key findings, such as which features best distinguish flower species.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpnqIg63LiAH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acBPPZF1LN1S"
      },
      "source": [
        "# **Case Study 2: Netflix Content Analysis** ðŸŽ¬  \n",
        "\n",
        "## **Background**  \n",
        "Netflix is a leading streaming platform with a vast collection of movies and TV shows. The company wants to analyze its **content library** to understand trends in **genres, release years, and regional distribution**.  \n",
        "\n",
        "## **Problem Statement**  \n",
        "How can we use **Netflixâ€™s dataset** to gain insights into content distribution, popular genres, and release trends over time?  \n",
        "\n",
        "## **Task Description**  \n",
        "\n",
        "### **1. Data Exploration**  \n",
        "- Load the dataset and inspect its structure.  \n",
        "- Identify key columns such as title, genre, release year, and country.  \n",
        "\n",
        "### **2. Data Cleaning**  \n",
        "- Check for missing or incorrect values in key columns.  \n",
        "- Remove duplicates and format the date-related data properly.  \n",
        "\n",
        "### **3. Basic Data Analysis**  \n",
        "- Count the number of movies vs. TV shows.  \n",
        "- Identify the most common genres and countries producing content.  \n",
        "- Analyze the number of releases per year to observe trends.  \n",
        "\n",
        "### **4. Insights & Interpretation**  \n",
        "- Summarize key findings, such as trends in Netflix's content production over time.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vrd7hTehLigX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
